#!/usr/bin/env python3
"""
Embedding Configuration for Glamhair Multi Comparator
Centralizes all embeddings-related settings and cost optimization parameters

Author: Peppe
Date: 2026-01-22
Version: 2.1 (FAISS + STIGA-STYLE EMBEDDINGS)
"""

from pathlib import Path
import os

# ============================================
# PROJECT PATHS
# ============================================
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / 'data'
LOGS_DIR = PROJECT_ROOT / 'logs'
MODELS_DIR = PROJECT_ROOT / 'models'

# Input data
PRODUCTS_FILE = DATA_DIR / 'products' / 'ALL_PRODUCTS_ENRICHED.json'

# Output directories (will be auto-created)
EMBEDDINGS_DIR = DATA_DIR / 'embeddings'
METADATA_DIR = EMBEDDINGS_DIR / 'metadata'
EMBEDDINGS_LOGS_DIR = LOGS_DIR / 'embeddings'

# Model cache directory
MODEL_CACHE_DIR = MODELS_DIR / 'embedding_model'

# ============================================
# EMBEDDING MODEL CONFIGURATION
# ============================================
EMBEDDING_MODEL = 'paraphrase-multilingual-mpnet-base-v2'

# Model specifications
MODEL_SPECS = {
    'name': EMBEDDING_MODEL,
    'dimensions': 768,
    'max_seq_length': 384,  # tokens
    'languages': ['it', 'en', 'fr', 'de', 'es', 'pt', 'nl', 'pl', 'ru', 'zh'],
    'batch_size': 32,
    'normalize_embeddings': True,
}

# Download settings
MODEL_DOWNLOAD = {
    'cache_dir': str(MODEL_CACHE_DIR),
    'force_download': False,  # Use cached if available
    'show_progress': True,
}

# ============================================
# FAISS CONFIGURATION
# ============================================
FAISS_CONFIG = {
    'index_type': 'IndexFlatIP',  # Inner Product (cosine similarity with normalized vectors)
    'index_file': str(EMBEDDINGS_DIR / 'faiss_index.bin'),
    'metadata_file': str(EMBEDDINGS_DIR / 'products_metadata.json'),
    'dimension': 768,  # Must match model dimensions
}

# Metadata fields to store (for efficient filtering)
METADATA_FIELDS = [
    'id',
    'nome',
    'brand',
    'categoria',
    'price',
    'price_range',
    'url',
    'immagine',
]

# ============================================
# EMBEDDING GENERATION SETTINGS
# ============================================
GENERATION_CONFIG = {
    'batch_size': 100,  # Products per batch
    'show_progress': True,
    'log_every_n_batches': 5,
    'save_checkpoint_every_n_batches': 10,  # For recovery
}

# Text preparation for embeddings (STIGA-STYLE: NO TRUNCATION)
TEXT_PREPARATION = {
    'max_description_length': None,   # FULL descrizione_completa
    'max_ingredienti_length': None,   # FULL ingredienti
    'max_benefici_length': None,      # FULL benefici
    'include_fields': [
        'nome',
        'brand',
        'categoria',
        'descrizione_completa',
        'ingredienti',
        'benefici',
        'tecnologie',
        'modo_uso',
        'regular_price',
    ],
}

# ============================================
# COST OPTIMIZATION & TOKEN TRACKING
# ============================================

# Dual-context architecture (as discussed)
RETRIEVAL_CONFIG = {
    'initial_retrieval': 50,   # Broad semantic search
    'after_reranking': 20,     # Final products to Claude
}

# Token estimation (for cost tracking)
TOKEN_ESTIMATION = {
    # Minimal format (for cached catalog)
    'per_product_minimal': 200,  # ID, nome, brand, categoria, prezzo
    
    # Detailed format (for top-20 context)
    'per_product_detailed': 500,  # Full: descrizione, ingredienti, benefici
    
    # System prompt (will be cached)
    'system_prompt': 5000,
    
    # Full catalog minimal (will be cached)
    'full_catalog_cached': 2619 * 200,  # ~524k tokens
    
    # Top-20 detailed (NOT cached, per query)
    'top_20_context': 20 * 500,  # ~10k tokens
    
    # Conversation history average
    'conversation_history': 2000,
}

# Cost per call estimation (Claude Sonnet 4)
COST_ESTIMATION = {
    # Input costs
    'input_no_cache_per_1m': 3.00,      # $3/M tokens
    'input_cache_write_per_1m': 3.75,   # $3.75/M tokens
    'input_cache_read_per_1m': 0.30,    # $0.30/M tokens
    
    # Output costs
    'output_per_1m': 15.00,             # $15/M tokens
    
    # Estimated per-call breakdown
    'per_call': {
        'input_cached': 524_000,        # Full catalog (cached)
        'input_fresh': 12_000,          # Top-20 + history + query
        'output': 500,                  # Response
        
        # Cost calculation (with cache hit)
        'cost_cached': 524_000 * 0.30 / 1_000_000,      # $0.157
        'cost_fresh': 12_000 * 3.00 / 1_000_000,        # $0.036
        'cost_output': 500 * 15.00 / 1_000_000,         # $0.0075
        'total': 0.051,  # ~$0.051 per call
    },
}

# Daily/monthly budgets (for rate limiting)
BUDGET_LIMITS = {
    'max_cost_per_day': 60.00,      # $60/day
    'max_cost_per_month': 1500.00,  # $1,500/month
    'max_conversations_per_day': 1000,
}

# ============================================
# SEARCH QUALITY SETTINGS
# ============================================
SEARCH_CONFIG = {
    'similarity_threshold': 0.5,  # Minimum cosine similarity
    'max_results': 50,            # Maximum results to return
    'enable_mmr': False,          # Maximal Marginal Relevance (diversity)
    'mmr_lambda': 0.5,            # Balance relevance vs diversity
}

# Reranking weights (for intelligent reranking)
RERANKING_WEIGHTS = {
    'semantic_similarity': 1.0,    # Base score from vector search
    'price_match': 0.3,            # Boost if within budget
    'brand_preference': 0.2,       # Boost for mentioned brands
    'category_exact': 0.4,         # Boost for exact category match
    'in_stock': 0.1,               # Future: boost in-stock items
}

# ============================================
# LOGGING CONFIGURATION
# ============================================
LOGGING_CONFIG = {
    'level': 'INFO',
    'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    'datefmt': '%Y-%m-%d %H:%M:%S',
    'log_to_file': True,
    'log_to_console': True,
}

# Log files
LOG_FILES = {
    'generation': EMBEDDINGS_LOGS_DIR / 'generation.log',
    'errors': EMBEDDINGS_LOGS_DIR / 'errors.log',
    'costs': EMBEDDINGS_LOGS_DIR / 'costs.log',
}

# ============================================
# MONITORING & DIAGNOSTICS
# ============================================
MONITORING_CONFIG = {
    'track_generation_time': True,
    'track_memory_usage': True,
    'track_token_usage': True,
    'track_costs': True,
    'save_diagnostics': True,
}

# Diagnostics output
DIAGNOSTICS_FILE = METADATA_DIR / 'diagnostics.json'
GENERATION_STATS_FILE = METADATA_DIR / 'generation_stats.json'

# ============================================
# ERROR HANDLING
# ============================================
ERROR_HANDLING = {
    'max_retries': 3,
    'retry_delay': 5,  # seconds
    'skip_on_error': True,  # Skip failed products instead of crashing
    'save_failed_products': True,
    'failed_products_file': METADATA_DIR / 'failed_products.json',
}

# ============================================
# HELPER FUNCTIONS
# ============================================

def ensure_directories():
    """Create all required directories if they don't exist"""
    directories = [
        DATA_DIR,
        EMBEDDINGS_DIR,
        METADATA_DIR,
        EMBEDDINGS_LOGS_DIR,
        MODELS_DIR,
        MODEL_CACHE_DIR,
    ]
    
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)
        print(f"âœ… Directory ready: {directory}")

def get_embedding_text(product: dict) -> str:
    """
    STIGA-STYLE: Prepare rich text for embedding from product data
    
    Key differences from previous version:
    - NO truncation of descriptions (use FULL text)
    - Category boost (3x repetition like STIGA)
    - Brand boost (2x repetition)
    - Keywords extraction from multiple fields
    - Separator " | " instead of "\\n"
    - Full ingredienti, benefici, tecnologie (no limits)
    
    Args:
        product: Product dictionary with all fields
        
    Returns:
        Formatted text ready for embedding (rich, no truncation)
    """
    parts = []
    
    # 1. CATEGORIA BOOST (3x ripetuta come STIGA per strong category signal)
    categoria = product.get('categoria', 'prodotto')
    parts.append(f"{categoria} {categoria} {categoria}")
    
    # 2. NOME PRODOTTO (FULL)
    nome = product.get('nome', '')
    if nome:
        parts.append(nome)
    
    # 3. BRAND BOOST (ripetuto 2x per strong brand signal)
    brand = product.get('brand', '')
    if brand:
        parts.append(f"{brand} {brand}")
    
    # 4. DESCRIZIONE COMPLETA (NO TRUNCATE - use FULL text!)
    descrizione = product.get('descrizione_completa', '')
    if descrizione:
        parts.append(descrizione)
    
    # 5. INGREDIENTI (FULL - no truncation)
    ingredienti = product.get('ingredienti', '')
    if ingredienti:
        parts.append(f"Ingredienti: {ingredienti}")
    
    # 6. BENEFICI (FULL - no truncation)
    benefici = product.get('benefici', '')
    if benefici:
        parts.append(f"Benefici: {benefici}")
    
    # 7. TECNOLOGIE (FULL)
    tecnologie = product.get('tecnologie', '')
    if tecnologie:
        parts.append(f"Tecnologie: {tecnologie}")
    
    # 8. MODO USO (if available)
    modo_uso = product.get('modo_uso', '')
    if modo_uso:
        parts.append(f"Utilizzo: {modo_uso}")
    
    # 9. KEYWORDS ESTRATTE (come STIGA)
    keywords = []
    
    # Da brand
    if brand:
        keywords.append(brand.lower())
    
    # Da nome (parole chiave principali)
    if nome:
        # Estrai parole significative (>3 chars, skip numeri)
        nome_words = [w.lower() for w in nome.split() if len(w) > 3 and not w.isdigit()]
        keywords.extend(nome_words[:5])  # Max 5 parole dal nome
    
    # Da tecnologie (primi termini chiave)
    if tecnologie:
        tech_words = [w.lower() for w in tecnologie.split()[:5] if len(w) > 3]
        keywords.extend(tech_words)
    
    # Rimuovi duplicati e crea stringa keywords
    if keywords:
        unique_keywords = list(set(keywords))
        parts.append(f"Keywords: {', '.join(unique_keywords)}")
    
    # 10. PREZZO
    prezzo = product.get('regular_price', 0)
    if prezzo:
        parts.append(f"Prezzo: â‚¬{prezzo}")
    
    # Join con " | " come STIGA (migliore per semantic separation)
    return " | ".join(parts).strip()

def get_price_range(price: float) -> str:
    """
    Categorize price into range for filtering
    
    Args:
        price: Product price in euros
        
    Returns:
        Price range category
    """
    if price < 20:
        return '0-20'
    elif price < 50:
        return '20-50'
    elif price < 100:
        return '50-100'
    else:
        return '100+'

def estimate_total_cost(num_conversations: int, cache_hit_rate: float = 0.95) -> dict:
    """
    Estimate total cost for N conversations
    
    Args:
        num_conversations: Number of conversations to estimate
        cache_hit_rate: Expected cache hit rate (0.95 = 95%)
        
    Returns:
        Cost breakdown dictionary
    """
    cost_per_call = COST_ESTIMATION['per_call']
    
    # First call: cache write
    first_call_cost = (
        cost_per_call['input_cached'] * COST_ESTIMATION['input_cache_write_per_1m'] / 1_000_000 +
        cost_per_call['cost_fresh'] +
        cost_per_call['cost_output']
    )
    
    # Subsequent calls: cache read
    cached_call_cost = cost_per_call['total']
    
    # Calculate total
    num_cached_calls = int(num_conversations * cache_hit_rate)
    num_uncached_calls = num_conversations - num_cached_calls
    
    total_cost = (
        num_uncached_calls * first_call_cost +
        num_cached_calls * cached_call_cost
    )
    
    return {
        'total_conversations': num_conversations,
        'cache_hit_rate': cache_hit_rate,
        'uncached_calls': num_uncached_calls,
        'cached_calls': num_cached_calls,
        'cost_per_uncached': first_call_cost,
        'cost_per_cached': cached_call_cost,
        'total_cost': total_cost,
        'cost_per_conversation_avg': total_cost / num_conversations,
    }

# ============================================
# VALIDATION
# ============================================

def validate_config():
    """Validate configuration settings"""
    errors = []
    
    # Check if products file exists
    if not PRODUCTS_FILE.exists():
        errors.append(f"Products file not found: {PRODUCTS_FILE}")
    
    # Check batch sizes are reasonable
    if GENERATION_CONFIG['batch_size'] > 500:
        errors.append("Batch size too large (max 500 recommended)")
    
    # Check cost limits are set
    if BUDGET_LIMITS['max_cost_per_day'] <= 0:
        errors.append("Invalid daily cost limit")
    
    if errors:
        print("âŒ Configuration Errors:")
        for error in errors:
            print(f"   â€¢ {error}")
        return False
    
    print("âœ… Configuration valid")
    return True

# ============================================
# INITIALIZATION
# ============================================

if __name__ == '__main__':
    """Test configuration and create directories"""
    print("ðŸ”§ Glamhair Embeddings Configuration")
    print("=" * 50)
    
    print("\nðŸ“ Creating directories...")
    ensure_directories()
    
    print("\nâœ… Validating configuration...")
    validate_config()
    
    print("\nðŸ“Š Configuration Summary:")
    print(f"   â€¢ Model: {EMBEDDING_MODEL}")
    print(f"   â€¢ Dimensions: {MODEL_SPECS['dimensions']}")
    print(f"   â€¢ Products file: {PRODUCTS_FILE}")
    print(f"   â€¢ FAISS index: {FAISS_CONFIG['index_file']}")
    print(f"   â€¢ Metadata file: {FAISS_CONFIG['metadata_file']}")
    print(f"   â€¢ Batch size: {GENERATION_CONFIG['batch_size']}")
    print(f"   â€¢ Embedding style: STIGA (NO truncation, category/brand boost)")
    
    print("\nðŸ’° Cost Estimation (per call):")
    cost = COST_ESTIMATION['per_call']
    print(f"   â€¢ Input cached: ${cost['cost_cached']:.4f}")
    print(f"   â€¢ Input fresh: ${cost['cost_fresh']:.4f}")
    print(f"   â€¢ Output: ${cost['cost_output']:.4f}")
    print(f"   â€¢ Total: ${cost['total']:.4f}")
    
    print("\nðŸ’° Cost Projections:")
    for num_conv in [100, 500, 1000]:
        estimate = estimate_total_cost(num_conv)
        print(f"   â€¢ {num_conv} conversations: ${estimate['total_cost']:.2f} (${estimate['cost_per_conversation_avg']:.4f}/conv)")
    
    print("\nâœ… Configuration ready!")